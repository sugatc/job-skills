{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXKE6M_8ZUb9"
      },
      "source": [
        "#Allow Drive Access"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IQzUec1Yyc4",
        "outputId": "ac23ddff-6cc5-42b8-f675-01027963b7dd"
      },
      "source": [
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Dependencies"
      ],
      "metadata": {
        "id": "wmieo3XrKWUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --upgrade fasttext\n",
        "!pip install gensim==4.2.0\n",
        "!pip install adjustText\n",
        "!pip install umap-learn\n",
        "!pip install hdbscan"
      ],
      "metadata": {
        "id": "i_8-Z4u1gBP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flGRnBlt4a5F"
      },
      "source": [
        "# Imports and Declaring Constants"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import fasttext\n",
        "import pandas as pd\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "from gensim.utils import simple_preprocess\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from adjustText import adjust_text\n",
        "from multiprocessing import Pool\n",
        "from scipy.spatial.distance import cosine\n",
        "import umap.umap_ as umap\n",
        "import hdbscan\n",
        "from adjustText import adjust_text\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Vh80iItCi9PL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set path and file names\n",
        "path = '/content/drive/My Drive/skill_bias_jobs/data/'\n",
        "mpath = '/content/drive/My Drive/skill_bias_jobs/model/'\n",
        "\n",
        "#Input file name:\n",
        "file = 'skills_jd.csv'\n",
        "\n",
        "#Created file names:\n",
        "textfile = 'jd.txt'\n",
        "skill_file = 'skill_count.csv'\n",
        "skill_association_file = 'skill_bias_words.csv'\n",
        "clustering_file = 'skill_cluster_hdbscan.csv'\n",
        "modelfile = 'jobs_fasttext.bin'"
      ],
      "metadata": {
        "id": "RALQj1Y4UWGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training FastText"
      ],
      "metadata": {
        "id": "LA_6BHtTUBaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and Preparing Data"
      ],
      "metadata": {
        "id": "xbrK4tAQuzk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(path+file)\n",
        "\n",
        "df.job_title.fillna('', inplace = True)\n",
        "df.description.fillna('', inplace = True)\n",
        "df.job_title = df.job_title.str.strip()\n",
        "df.description = df.description.str.strip()\n",
        "\n",
        "df['job_title'] = df['job_title'].astype(str) + ' ' +  df['description'].astype(str)\n",
        "df = df.drop(['description'], axis=1)\n",
        "\n",
        "#Further preprocessing\n",
        "df['job_title'] = [[word for word in simple_preprocess(str(doc),deacc=False, min_len=1, max_len=30)] for doc in df['job_title']]\n",
        "df['job_title'] = df['job_title'].map(lambda tokens: ' '.join(tokens))\n",
        "\n",
        "#Fasttext requires text file; saving as text file\n",
        "with open(path + textfile, 'w') as f:\n",
        "    for line in df['job_title'].values:\n",
        "        f.write(line)\n",
        "        f.write('\\n')\n",
        "\n",
        "#Generating a skills dictionary\n",
        "df = df.drop(['job_title'], axis=1)\n",
        "\n",
        "df.key_skills.fillna('', inplace = True)\n",
        "df.key_skills = df.key_skills.str.strip()\n",
        "\n",
        "#Further preprocessing for skills\n",
        "df['key_skills'] = [[word for word in simple_preprocess(str(doc),deacc=False, min_len=2, max_len=30)] for doc in df['key_skills']]\n",
        "df['key_skills'] = df['key_skills'].map(lambda tokens: ' '.join(tokens))\n",
        "\n",
        "#Skills dictionary with frequency\n",
        "def tokenizer(s):\n",
        "   return s.split(',')\n",
        "word_vectorizer = CountVectorizer(max_features=100000, min_df=0, max_df=1.0, analyzer='word', ngram_range=(1,1), tokenizer = tokenizer, lowercase = False, binary=True)\n",
        "sparse_matrix = word_vectorizer.fit_transform(df.key_skills)\n",
        "frequencies = sum(sparse_matrix).toarray()[0]\n",
        "df = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names_out(), columns=['frequency'])\n",
        "\n",
        "df.to_csv(path + skill_file)\n",
        "\n",
        "del df"
      ],
      "metadata": {
        "id": "uzasUNWBCzF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training and saving the domain specific model"
      ],
      "metadata": {
        "id": "xWzD3scpUIS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = fasttext.train_unsupervised(path + textfile, minn=3, maxn=6, dim=300, epoch = 10, lr = 0.05)\n",
        "model.save_model(mpath + modelfile)"
      ],
      "metadata": {
        "id": "rkzTYJ_-udBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Retrieving Embeddings"
      ],
      "metadata": {
        "id": "JeG8hcDGu4yg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Skills and Fasttext model"
      ],
      "metadata": {
        "id": "W4_OqD1mcy_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load skill dictionary and domain specific Fasttext\n",
        "df = pd.read_csv(path + skill_file)\n",
        "\n",
        "#Dropping empty skills\n",
        "df['Unnamed: 0'].fillna('', inplace = True)\n",
        "df = df[df['Unnamed: 0']!=\"\"]\n",
        "\n",
        "model = fasttext.load_model(mpath + modelfile)"
      ],
      "metadata": {
        "id": "W-4L7eNCcOBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511768a9-d5b2-4eff-d989-1285388447d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To download the pre-trained English model (note: this is quite heavy)\n",
        "fasttext.util.download_model('en', if_exists='ignore')\n",
        "model_pre = fasttext.load_model('cc.en.300.bin')"
      ],
      "metadata": {
        "id": "wwrEDHo4VrtM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d6f18d3-b203-4cc0-c89b-6db26c79c91c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtaining Cosine similarity with gender attribute words"
      ],
      "metadata": {
        "id": "7o1HVvK-W6hG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cosine similarities with the words female and male only using domain specific embeddings\n",
        "def cosine_similarity_female(skill):\n",
        "  return 1- cosine(model[skill], model['female'])\n",
        "\n",
        "def cosine_similarity_male(skill):\n",
        "  return 1 - cosine(model[skill], model['male'])\n",
        "\n",
        "#Average cosine similarities with all gender attribute words using domain specific embeddings\n",
        "def cosine_similarity_female_avg(skill):\n",
        "  return 1- (cosine(model[skill], model['female']) + cosine(model[skill], model['females']) + cosine(model[skill], model['woman']) + cosine(model[skill], model['women']) +\n",
        "             cosine(model[skill], model['girl']) + cosine(model[skill], model['girls']) + cosine(model[skill], model['lady']) + cosine(model[skill], model['ladies']) +\n",
        "             cosine(model[skill], model['feminine']))/9\n",
        "\n",
        "def cosine_similarity_male_avg(skill):\n",
        "  return 1 - (cosine(model[skill], model['male']) + cosine(model[skill], model['males']) + cosine(model[skill], model['man']) + cosine(model[skill], model['men']) +\n",
        "              cosine(model[skill], model['boy']) + cosine(model[skill], model['boys']) + cosine(model[skill], model['gent']) + cosine(model[skill], model['gents']) +\n",
        "              cosine(model[skill], model['guy']) + cosine(model[skill], model['guys']) + cosine(model[skill], model['masculine']))/11\n",
        "\n",
        "#Cosine similarities using the pre-trained model\n",
        "def cosine_similarity_female2(skill):\n",
        "  return 1- cosine(model_pre[skill], model_pre['female'])\n",
        "\n",
        "def cosine_similarity_male2(skill):\n",
        "  return 1 - cosine(model_pre[skill], model_pre['male'])"
      ],
      "metadata": {
        "id": "T7bk75xGijta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating Similarity with Female\n",
        "p = Pool(2)\n",
        "df['cosine_female'] = p.map(cosine_similarity_female, df['Unnamed: 0'])\n",
        "p.close()\n",
        "p.join()\n",
        "\n",
        "#Calculating Similarity with Male\n",
        "p = Pool(2)\n",
        "df['cosine_male'] = p.map(cosine_similarity_male, df['Unnamed: 0'])\n",
        "p.close()\n",
        "p.join()\n",
        "\n",
        "#Calculating Similarity with Female using all gender attribute words\n",
        "p = Pool(2)\n",
        "df['cosine_female_avg'] = p.map(cosine_similarity_female_avg, df['Unnamed: 0'])\n",
        "p.close()\n",
        "p.join()\n",
        "\n",
        "#Calculating Similarity with Male using all gender attribute words\n",
        "p = Pool(2)\n",
        "df['cosine_male_avg'] = p.map(cosine_similarity_male_avg, df['Unnamed: 0'])\n",
        "p.close()\n",
        "p.join()\n",
        "\n",
        "\n",
        "#Calculating Similarity with Female pre-trained\n",
        "p = Pool(2)\n",
        "df['cosine_female_pre'] = p.map(cosine_similarity_female2, df['Unnamed: 0'])\n",
        "p.close()\n",
        "p.join()\n",
        "\n",
        "#Calculating Similarity with Male pre-trained\n",
        "p = Pool(2)\n",
        "df['cosine_male_pre'] = p.map(cosine_similarity_male2, df['Unnamed: 0'])\n",
        "p.close()\n",
        "p.join()\n",
        "\n",
        "df.to_csv(path + skill_association_file, index=False)\n",
        "\n",
        "del df"
      ],
      "metadata": {
        "id": "LFv23iH-kH83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Skill Clustering"
      ],
      "metadata": {
        "id": "5Si1PvlyAOLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the file with skill associations (load Fasttext again if required)\n",
        "model = fasttext.load_model(mpath + modelfile)\n",
        "\n",
        "df = pd.read_csv(path + skill_association_file)\n",
        "df['Unnamed: 0'].fillna('', inplace = True)\n",
        "df = df[df['Unnamed: 0']!=\"\"]\n",
        "\n",
        "df['female_bias'] = np.sign(df['cosine_female'] - df['cosine_male'])\n",
        "\n",
        "#Restricting the sample to skills that occur in more than 10 job ads\n",
        "df = df[df['frequency']>10]"
      ],
      "metadata": {
        "id": "xe1nQeJooUED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67481a08-f54f-4b11-bc4e-d9ec0ebb9b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtaining embeddings\n",
        "def embeddings(skill):\n",
        "  return model[skill]\n",
        "\n",
        "p = Pool(4)\n",
        "df['embeddings'] = p.map(embeddings, df['Unnamed: 0'])\n",
        "p.close()\n",
        "p.join()\n",
        "\n",
        "x = df['embeddings'].values\n",
        "x = np.concatenate(x, axis=0).reshape(len(x),300)"
      ],
      "metadata": {
        "id": "2fv7uzMsA1ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using UMAP for reducing dimensions; read here: https://umap-learn.readthedocs.io/en/latest/ (note: n_neighbor 20->200 doesn't significantly change visualization)\n",
        "x_umap = umap.UMAP(n_neighbors = 20, random_state=42, n_components = 2, min_dist = 0, metric = 'cosine').fit_transform(x)\n",
        "df['umap0'] = x_umap[:, 0]\n",
        "df['umap1'] = x_umap[:, 1]\n",
        "\n",
        "#Using HDBSCAN for clustering; read here: https://hdbscan.readthedocs.io/en/latest/\n",
        "clusterer = hdbscan.HDBSCAN(metric='euclidean', min_cluster_size=20, min_samples = 1, cluster_selection_epsilon = .2, cluster_selection_method = 'eom')\n",
        "clusterer.fit(x_umap)\n",
        "df['cluster'] = clusterer.labels_\n",
        "df['cluster_prob'] = clusterer.probabilities_\n",
        "\n",
        "df.to_csv(path + clustering_file, index = False)"
      ],
      "metadata": {
        "id": "cyPKT7-x4VSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizations"
      ],
      "metadata": {
        "id": "2NLGS5n0GOwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading and cleaning data\n",
        "df = pd.read_csv(path + clustering_file)\n",
        "\n",
        "#Choosing only top n words by frequency and coloring based on cluster\n",
        "topn = 4\n",
        "\n",
        "#Removing noise, skills that can't be classified, and keeping only top 4 in each category\n",
        "dk = df[df['cluster']!=-1]\n",
        "dk = dk[dk['Unnamed: 0']!='high school pass']\n",
        "dk = dk[dk['Unnamed: 0']!='axis']\n",
        "dk = dk[dk['Unnamed: 0']!='district']\n",
        "dk = dk[dk['Unnamed: 0']!='bengal']\n",
        "dk = dk[dk['Unnamed: 0']!='hs']\n",
        "dk = dk[dk['Unnamed: 0']!='basic computer'] #repeated\n",
        "dk = dk[dk['Unnamed: 0']!='good communication'] #repeated\n",
        "dk = dk[dk['Unnamed: 0']!='communication skills'] #repeated\n",
        "dk = dk.groupby(['cluster']).apply(lambda x: x.nlargest(topn, columns = ['frequency']))\n",
        "\n",
        "# #Removing clusters having names or educational degree\n",
        "dk = dk[dk['cluster']!=6]\n",
        "dk = dk[dk['cluster']!=18]\n",
        "\n",
        "#Computing gender bias and normalization to display colors\n",
        "dk['female_bias'] = dk['cosine_female'] - dk['cosine_male']\n",
        "# df['female_bias'] = np.sign(df['female_bias'])\n",
        "max = dk['female_bias'].max()\n",
        "min = dk['female_bias'].min()\n",
        "\n",
        "dk[\"female_bias\"] = np.where(dk[\"female_bias\"]<0, -dk[\"female_bias\"]/min, dk[\"female_bias\"])\n",
        "dk[\"female_bias\"] = np.where(dk[\"female_bias\"]>0, dk[\"female_bias\"]/max, dk[\"female_bias\"])"
      ],
      "metadata": {
        "id": "-XUy8G_vNLl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skill Cluster Visualization"
      ],
      "metadata": {
        "id": "7jJmJnB0jDw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Skills map (This is used to produce Figure 2 in the paper)\n",
        "fig, ax = plt.subplots(figsize=(40,40))\n",
        "\n",
        "ax.scatter(dk['umap0'], dk['umap1'], s = dk['frequency']/2, c = dk['cluster'], cmap='Spectral')\n",
        "\n",
        "plt.gca().axes.get_xaxis().set_visible(False)\n",
        "plt.gca().axes.get_yaxis().set_visible(False)\n",
        "\n",
        "texts = []\n",
        "for i, txt in enumerate(dk['Unnamed: 0']):\n",
        "    texts.append(ax.annotate(txt, (dk['umap0'].values[i], dk['umap1'].values[i]), size = 28))\n",
        "\n",
        "adjust_text(texts)"
      ],
      "metadata": {
        "id": "LwVBqsUAjLYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gender Association Visualization"
      ],
      "metadata": {
        "id": "YuNqLlnBjNi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Skill map with gender associations (This is used to produce Figure 3 in the paper)\n",
        "fig, ax = plt.subplots(figsize=(40,40))\n",
        "\n",
        "ax.scatter(dk['umap0'], dk['umap1'], s = dk['frequency']/2, c = dk['female_bias'], cmap='bwr')\n",
        "\n",
        "plt.gca().axes.get_xaxis().set_visible(False)\n",
        "plt.gca().axes.get_yaxis().set_visible(False)\n",
        "\n",
        "texts = []\n",
        "for i, txt in enumerate(dk['Unnamed: 0']):\n",
        "    texts.append(ax.annotate(txt, (dk['umap0'].values[i], dk['umap1'].values[i]), size = 28))\n",
        "\n",
        "adjust_text(texts)"
      ],
      "metadata": {
        "id": "5mcuCkiWhQyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EJnVeWBYzOUo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}