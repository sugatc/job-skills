{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXKE6M_8ZUb9"
      },
      "source": [
        "#Allow Drive Access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IQzUec1Yyc4",
        "outputId": "0ed51ae1-2c46-4851-ee87-54dcb97adbb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Dependencies"
      ],
      "metadata": {
        "id": "1HfVzF6V_-VF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_8-Z4u1gBP5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install fasttext==0.9.2\n",
        "!pip install gensim==4.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports and Declaring Constants"
      ],
      "metadata": {
        "id": "O4DPrHxnADd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import pandas as pd\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "from multiprocessing import Pool\n",
        "import numpy as np\n",
        "from gensim.utils import simple_preprocess\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from gensim.models.phrases import Phrases, ENGLISH_CONNECTOR_WORDS"
      ],
      "metadata": {
        "id": "yakfHFKeAKW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set paths and file names\n",
        "path = \"/content/drive/My Drive/skill_bias_jobs/data/\"\n",
        "mpath = \"/content/drive/My Drive/skill_bias_jobs/model/\"\n",
        "file = 'skills_jd.csv'\n",
        "mfile = 'jobs_fasttext.bin'\n",
        "topic_metrics_file = 'topic_number_metrics.csv'\n",
        "occupation_file = 'jt_occupation_fasttext.csv'\n",
        "occupation_label_file = 'occupation_labels_fasttext.csv'"
      ],
      "metadata": {
        "id": "TDgpnA-eAW82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Si1PvlyAOLQ"
      },
      "source": [
        "#Occupation Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe1nQeJooUED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6074d8f-f1cd-47e9-aecb-126b59a056f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "# Function to get sentence vectors\n",
        "def embeddings(title):\n",
        "  return model.get_sentence_vector(title)\n",
        "\n",
        "#Loading data\n",
        "df=pd.read_csv(path+file, encoding='ISO-8859-1', sep=',')\n",
        "df.job_title = df.job_title.str.strip()\n",
        "df.job_title.fillna('', inplace = True)\n",
        "df.description = df.description.str.strip()\n",
        "df.description.fillna('', inplace = True)\n",
        "df.drop(columns=['key_skills'], inplace=True)\n",
        "\n",
        "#Dropping duplicates in job title and description\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "#Loading Model\n",
        "model = fasttext.load_model(mpath + mfile)\n",
        "\n",
        "p = Pool(2)\n",
        "df['embeddings'] = p.map(embeddings, df['job_title']+ \" \" + df['description'])\n",
        "p.close()\n",
        "p.join()\n",
        "\n",
        "x = df['embeddings'].values\n",
        "x = np.concatenate(x, axis=0).reshape(len(x),300)\n",
        "\n",
        "df.drop(columns=['embeddings'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeYx-7oj8xcs"
      },
      "source": [
        "## Finding cluster number based on elbow rule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BdCpDND6cPc"
      },
      "outputs": [],
      "source": [
        "inertias = []\n",
        "total_clusters = []\n",
        "for k in range(10,1000,10):\n",
        "    kmeans = KMeans(n_clusters = k, random_state=42)\n",
        "    kmeans.fit(x)\n",
        "    x_pred = kmeans.predict(x)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "    total_clusters.append(k)\n",
        "\n",
        "dj = pd.DataFrame({'total_clusters':total_clusters,'inertias':inertias})\n",
        "dj.to_csv(path+topic_metrics_file, index=False)\n",
        "\n",
        "#Plotting inertia against number of clusters\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(total_clusters, inertias, 'bx-')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Inertia')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7i5rQuapkXb"
      },
      "source": [
        "## Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62E8ZOAlpkXd"
      },
      "outputs": [],
      "source": [
        "#Kmeans: elbow rule suggests around 300 occupations\n",
        "kmeans = KMeans(n_clusters = 300, random_state = 42)\n",
        "kmeans.fit(x)\n",
        "df['cluster_knn'] = kmeans.predict(x)\n",
        "\n",
        "df.to_csv(path+occupation_file, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHaqMcrekUHj"
      },
      "source": [
        "# Occupation Labeling based on Job Titles\n",
        "Note: This helps in understanding the main content in occupation clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmJkYdCMkUHk"
      },
      "outputs": [],
      "source": [
        "#Setting stopwords\n",
        "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him',\n",
        "              'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who',\n",
        "              'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did',\n",
        "              'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
        "              'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then',\n",
        "              'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only',\n",
        "              'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y',\n",
        "              'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma',\n",
        "              'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\",\n",
        "              'wouldn', \"wouldn't\", 'cum', 'urgent', 'requirement', 'boy', 'required', 'job', 'jobs', 'iii', 'iv', 'etc', 'th', 'salary', 'chennai', 'women', 'wanted',\n",
        "              'ahmedabad', 'bangalore', 'walkin', 'ctc', 'walking', 'walk', 'earn', 'delhi', 'new', 'role', 'homes', 'working', 'two', 'way', 'interview', 'pm', 'person',\n",
        "              'saturday', 'sunday', 'feb', 'hiring', 'need', 'ii', 'female', 'winter', 'pre',\n",
        "              'final', 'candidates', 'candidate', 'west', 'get', 'years', 'year', 'lpa', 'big', 'per', 'month', 'coimbatore',\n",
        "              'black', 'white', 'indiranagar', 'australian', 'inside', 'apply', 'available', 'amazon', 'pvt', 'limited', 'looking', 'patna', 'world',\n",
        "              'one', 'male', 'multiple', 'basis', 'immediate', 'opputunity', 'females', 'woman', 'girls', 'girl', 'ladies', 'lady', 'males', 'man', 'men', 'guy', 'guys', 'boys',\n",
        "              'gents', 'gent', 'good', 'opportunity', 'letter', 'upto', 'non', 'mahindra', 'us',\n",
        "              'shortlisted', 'ambattur', 'opening', 'infosys', 'openings', 'accenture', 'results', 'waiting', 'gross', 'malaysia',\n",
        "              'cv', 'resume', 'drive', 'position', 'offer', 'sal', 'profile', 'contact', 'spot', 'mega', 'firm',\n",
        "              'short', 'lacs', 'listed', 'ltd', 'leading', 'rina', 'india', 'others', 'nikitha', 'excellent', 'noida', 'also', 'co',\n",
        "              'indianmoney', 'based', 'mounika', 'syed', 'deepika', 'hire', 'udhyog', 'bharat',\n",
        "              'invites', 'technologies', 'august', 'consultancy', 'huge', 'best', 'location', 'uk', 'tuesday',\n",
        "              'kind', 'attention', 'face', 'level', 'lac', 'package', 'convergys', 'hyderabad', 'reputed', 'mumbai', 'ricago', 'walkout', 'bizknowmics', 'free',\n",
        "              'congratulations', 'currently', 'vacancy', 'hc', 'ntpc', 'honda', 'samsung', 'siel', 'step', 'thursday', 'june', 'koramangala', 'interviews',\n",
        "              'selected', 'sector', 'concentrix', 'well', 'leo', 'include', 'eligible', 'industry', 'invite', 'october', 'cube', 'thane', 'cal', 'rally', 'st',\n",
        "              'private', 'hp', 'rakesh', 'kolkata', 'open', 'dell', 'july', 'hdfc', 'indirapuram', 'april', 'tesco', 'sun', 'september', 'malakpet', 'place', 'permit',\n",
        "              'usa', 'companies', 'registered', 'sunita', 'dec', 'try', 'nehru', 'startups', 'organisation', 'oct', 'urgently', 'rivera',\n",
        "              'cryoviva', 'bigbasket', 'opportunities', 'december', 'sat', 'de', 'appointment', 'reminder', 'servicenow', 'murali',\n",
        "              'invitation', 'small', 'includes', 'gurgaon', 'may', 'make', 'chaithra', 'requirements', 'next', 'icici', 'joining', 'opeinig',\n",
        "              'cnx', 'headquartered', 'colorado', 'hurry', 'monday', 'summer', 'varsha', 'jan', 'swiggy', 'nterview', 'hana', 'passion', 'anyone', 'bold', 'kora',\n",
        "              'joinees', 'batch', 'lakhs', 'nov', 'sub', 'ahmadabad', 'nagar', 'dreamgains', 'january', 'nj', 'south', 'kondapur', 'kotak',\n",
        "              'genpact', 'yrs', 'verma', 'ashish', 'ranchi', 'locality', 'start', 'birla', 'aditya', 'jamnagar', 'require', 'week',\n",
        "              'omega', 'shubhalaxmi', 'nirman', 'vinay', 'geekay', 'wns', 'parel', 'join', 'flipkart', 'range', 'plus', 'exl', 'adeeba', 'friday', 'limit',\n",
        "              'jana', 'date', 'shortlist', 'national', 'kolkatta', 'rajkot', 'future', 'hari', 'tcs', 'keerthi', 'east', 'pue', 'exceutive', 'park', 'haryana', 'loc',\n",
        "              'mangalore', 'super', 'thywill', 'jaipur', 'paytm', 'citi', 'quota', 'gachibowli', 'grab', 'details', 'description', 'guarantee', 'become',\n",
        "              'jayanagar', 'opportinities', 'ghaziabad', 'rounds', 'indore', 'like', 'left', 'basheera', 'hyd', 'mid', 'solidworks', 'swathi', 'paid',\n",
        "              'hring', 'nandith', 'nagpur', 'mar', 'ariba', 'away', 'tomorrow', 'hirng', 'pan', 'hiya', 'oriented', 'grow', 'excellence', 'congratulation', 'indiaranagar',\n",
        "              'ways', 'ten', 'wait', 'ample', 'jp', 'lucknow', 'sandhya', 'yr', 'sooner', 'bujji', 'exciting', 'avaya', 'ludhiana', 'sept', 'banca',\n",
        "              'sukanya', 'nischal', 'gentle', 'chandigarh', 'bengal', 'harsh', 'shivangi', 'gujarat', 'going', 'months', 'wonders', 'jenifer', 'vijayanagar', 'asha', 'using',\n",
        "              'go', 'various', 'ltmd', 'surat', 'days', 'tivoli', 'aug', 'sametime', 'great', 'want', 'naaz', 'gurugram', 'north', 'assam', 'november', 'jyoti',\n",
        "              'persons', 'addl', 'ranjangaon', 'sep', 'hired', 'jdedwards', 'yalamanchili', 'ltocas', 'sandstone', 'growe', 'locations', 'kalyani', 'pavithra', 'followed',\n",
        "              'wipro', 'sbi', 'chhattisgarh', 'know', 'oppurtunity', 'saket', 'opporunities', 'mukesh', 'shruthi', 'prefered', 'preferred', 'later', 'getting', 'opportunityfor',\n",
        "              'stay', 'carefully', 'asia', 'jagatpura', 'reetu', 'walkins', 'opportunies', 'jai', 'allahabad', 'farha', 'please', 'near', 'goregaon',\n",
        "              'sablaa', 'interested', 'third', 'ncr', 'zoya', 'salem', 'edwards', 'australia', 'padma', 'xi', 'joiner', 'joiners', 'kovaipudur', 'monthly',\n",
        "              'balrampur', 'aakash', 'smriti', 'madurai', 'uae', 'freshersfemale', 'weekdays', 'nasik', 'given', 'purnima', 'poornima', 'mens', 'wednesday', 'oppurtunties',\n",
        "              'rajani', 'madhapur', 'mohan', 'pali', 'genuine', 'aditi', 'met', 'raj', 'mishresh', 'lkh', 'lk', 'bhilwara', 'arnold', 'shorltisted', 'outs',\n",
        "              'chandivali', 'vietnam', 'womens', 'greet', 'badarpur', 'yearas', 'vizag', 'lahari', 'soon', 'vaccancy', 'rich', 'lower', 'fair', 'dubai', 'bandhan','axis', 'graduate', 'andheri','pune',\n",
        "              'jamshedpur','married','preet','marriott','navi','shomik','dasgupta','day','shift','notice','work','flexible','selection']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o8yvZp1kUHl",
        "outputId": "aba0b908-025d-4786-b440-21e6f6a99de3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-20235ce97c3b>:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df.job_title = df.job_title.str.replace('[^0-9a-zA-Z]+', ' ')\n"
          ]
        }
      ],
      "source": [
        "#Cleaning title\n",
        "df = pd.read_csv(path + occupation_file)\n",
        "\n",
        "#Convert to lower case\n",
        "df.job_title = df.job_title.str.lower()\n",
        "\n",
        "#Keep only alphabets and numbers\n",
        "df.job_title = df.job_title.str.replace('[^0-9a-zA-Z]+', ' ')\n",
        "df.job_title.fillna('', inplace = True)\n",
        "\n",
        "#Remove return and other things\n",
        "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "\n",
        "#Removing leading and trailing spaces\n",
        "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "\n",
        "#Removing Extra Spaces\n",
        "df['job_title'] = df['job_title'].replace('\\s+', ' ', regex=True)\n",
        "\n",
        "# Stop word removal\n",
        "df['job_title'] = [[word for word in simple_preprocess(str(doc),deacc=False, min_len=2, max_len=30) if word not in stop_words] for doc in df['job_title']]\n",
        "df['job_title'] = df['job_title'].map(lambda tokens: ' '.join(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeJR26NxkUHl"
      },
      "source": [
        "##Getting phrases from titles using bigram pasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyuPzpRekUHm"
      },
      "outputs": [],
      "source": [
        "#Training phrase model\n",
        "sentences = df['job_title'].to_list()\n",
        "sentences = [doc.split(\" \") for doc in sentences]\n",
        "\n",
        "phrase_model = Phrases(sentences, connector_words=ENGLISH_CONNECTOR_WORDS, scoring = 'npmi', threshold=-1)\n",
        "\n",
        "del sentences\n",
        "\n",
        "#Transforming job titles\n",
        "def bigram_pasting(sentence):\n",
        "  return \" \".join(phrase_model[sentence.split(\" \")])\n",
        "\n",
        "p = Pool(2)\n",
        "df['job_title'] = p.map(bigram_pasting, df['job_title'])\n",
        "p.close()\n",
        "p.join()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wApXSN_kUHm"
      },
      "source": [
        "##Obtaining TF-IDF-based labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfNCx75ZkUHm"
      },
      "outputs": [],
      "source": [
        "#Joining all documents belonging to a given topic\n",
        "docs_per_topic = df.groupby(['cluster_knn'], as_index = False).agg({'job_title': ' '.join})\n",
        "\n",
        "#Obtaining TF-IDF scores\n",
        "def c_tf_idf(documents, m, ngram_range=(1, 1)):\n",
        "    count = CountVectorizer(ngram_range=ngram_range, stop_words=\"english\").fit(documents)\n",
        "    t = count.transform(documents).toarray()\n",
        "    w = t.sum(axis=1)\n",
        "    tf = np.divide(t.T, w)\n",
        "    sum_t = t.sum(axis=0)\n",
        "    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n",
        "    tf_idf = np.multiply(tf, idf)\n",
        "\n",
        "    return tf_idf, count\n",
        "\n",
        "tf_idf, count = c_tf_idf(docs_per_topic.job_title.values, m=len(df))\n",
        "\n",
        "#Extracting top 20 words for each occupation\n",
        "def extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20):\n",
        "    words = count.get_feature_names()\n",
        "    labels = list(docs_per_topic.cluster_knn)\n",
        "    tf_idf_transposed = tf_idf.T\n",
        "    indices = tf_idf_transposed.argsort()[:, -n:]\n",
        "    top_n_words = {label: [(words[j], tf_idf_transposed[i][j]) for j in indices[i]][::-1] for i, label in enumerate(labels)}\n",
        "    return top_n_words\n",
        "\n",
        "def extract_topic_sizes(df):\n",
        "    topic_sizes = (df.groupby(['cluster_knn'])\n",
        "                     .ti\n",
        "                     .count()\n",
        "                     .reset_index()\n",
        "                     .rename({\"cluster_knn\": \"Topic\", \"text\": \"Size\"}, axis='columns')\n",
        "                     .sort_values(\"Size\", ascending=False))\n",
        "    return topic_sizes\n",
        "\n",
        "top_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20)\n",
        "\n",
        "dj = pd.DataFrame(top_n_words)\n",
        "dj.to_csv(path + occupation_label_file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}